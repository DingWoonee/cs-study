# 동기화(Synchronization)
## 1 동기화의 개념과 필요성
- **동기화(Synchronization)의 개념**
    
    동기화란 여러 개의 스레드/프로세스가 공유 데이터를 안전하게 사용하도록 순서를 조절하는 기술을 말한다.
    
    → 데이터 무결성 보장 & Race Condition 방지
    
- **공유 자원(Shared Resource)**
    
    여러 스레드가 동시에 접근하거나 수정하려는 대상으로,  
    변수나 파일, DB 커넥션, CPU 캐시 라인 등이 있다.  
    → 동시에 접근하면 문제될 수 있는 것은 모두 Shared Resource임.
    
- **임계 구역(Critical Section)**
    
    둘 이상의 스레드가 동시에 들어가면 안 되는 코드 영역을 말한다.
    
    ex) 증감 연산자는 원자적으로 처리되지 않기 때문에 Critical Section이라고 할 수 있다.
    
- **Race Condition(경쟁 상태)**
    
    여러 스레드가 “누가 먼저 실행되느냐”에 따라 **결과가 달라지는** 상태를 말한다.  
    → 그 결과를 보장할 수 없는 경우
    
- **공유 메모리 구조 / 여러 스레드가 변수 하나를 공유할 때의 문제점**
    - Read-Modify-Write의 비원자성
        
        스레드가 절반만 수행하고 context switching이 일어날 경우 문제가 생길 수 있다.
        
    - CPU 캐시로 인해 보이는 값이 다를 수 있음 (맨아래의 MESI 프로토콜 참고)
    - 컴파일러 / CPU의 명령어 재배치(Reordering)
      
- **병렬성 vs 동시성**
    - **병렬성(Parallelism)**
        
        실제 여러 CPU에서 동시에 실행하는 것을 말한다.
        
        → 여러 코어가 동시에 하나의 값(공유 자원)을 수정하는 경우 문제 발생
        
    - **동시성(Concurrency)**
        
        실제로는 한 번에 하나씩 처리하지만 교대로 빠르게 번갈아 실행해서 동시에 실행하는 것처럼 보이는 것을 말한다.
        
        → 한 스레드가 작업 중인데 context switching이 일어나면서 race condition 발생
        
    
    ⇒ 어쨌거나 둘 다 동기화가 필요함.
    
- **동기화가 필요한 이유**
    - 데이터 무결성 유지
    - 실행 순서를 강제
    - 원자성을 보장
      
## 2 동기화 문제의 정의
    
동기화 문제들은 대부분 아래 둘 중 하나로 요약된다.

공유 자원에 대한 접근 순서 조절  
vs  
여러 작업 간의 진행 조건 조절

⇒ `공유 자원`, `필요한 동기화 조건`, `발생 가능한 문제`를 파악해야 한다.

### 2.1 생산자-소비자 문제
    
생산자와 소비자는 하나의 버퍼(큐)를 공유한다. 생산자는 버퍼에 데이터를 넣고, 소비자는 버퍼에서 데이터를 꺼낸다.

- **공유 자원** → 버퍼(큐)
- **필요한 동기화 조건**
    1. 버퍼의 같은 칸에 동시에 접근하면 안된다.
    2. 버퍼가 꽉 차면 생산자는 기다려야 한다.
    3. 버퍼가 비면 소비자는 기다려야 한다.
- **해결 방법**
    1. 뮤텍스나 세마포어, 모니터를 이용해서 버퍼 접근을 상호 배체(mutual exclusion)
    2. 버퍼가 “비었는지/가득찼는지”는 조건 변수나 세마포어로 제어
       
### 2.2 Bounded Buffer 문제
    
생산자-소비자 문제의 구체화 버전으로, 버퍼가 유한하다는 것이 핵심이다.

⇒ 이 역시 조건 변수나 세마포어로 버퍼가 “비었는지/가득찼는지”를 관리
    
### 2.3 Reader-Writer 문제
    
여러 스레드가 하나의 공유 데이터(DB, 파일)에 접근하는 경우이다.

- **공유 자원** → 데이터(DB, 파일)
- **필요한 동기화 조건**
    1. Reader(읽기): 데이터 읽기는 동시에 접근 가능
    2. Writer(쓰기): 데이터를 쓸 때는 Reader, Writer 누구도 접근할 수 없음
- **해결 방법**
    
    기본적으로는 readCount를 관리해서 뮤텍스로 락을 제어한다.
    
    → 근데 Starvation 문제가 있을 수 있다.  
    Writer 기아: Reader가 계속 들어오면 Writer는 영원히 실행할 수 없음  
    Reader 기아: Writer 우선순위 정책을 적용하면 Reader가 영원히 block될 수 있음
    
    → FIFO로 큐 방식을 통해 모두에게 공정성을 보장하는 방식이 있다.
    
- **솔루션 별 특징**
    
    **Reader 우선 솔루션**  
    → 읽기 작업이 매우 빈번한 경우에 적절
    
    **Writer 우선 솔루션**  
    → 데이터 일관성이 매우 중요하고 쓰기가 지연되면 안되는 경우에 적절
    
    **공정**  
    → 대기 큐(wait queue)를 두어 FIFO 방식으로 스레드의 진입 순서를 강제한다. (Java의 ReentrantReadWriteLock이 이런 방식이다.)  
    → 실무/운영체제에서 가장 선호되는 방식이다.
        
### 2.4 Dining Philosophers(식사하는 철학자) 문제
    
둥근 테이블에 철학자 N명이 앉아있고, 각 철학자 사이에는 포크가 1개씩 있어서 포크도 총 N개가 있다.  
철학자는 자기 기준 양옆의 두 포크를 모두 잡아야 식사가 가능하다.

- **공유 자원** → 포크
- **발생 가능한 문제**
    - Deadlock
        
        모든 철학자가 동시에 모두 왼쪽 포크를 잡음 → Deadlock
        
    - Starvation
        
        특정 철학자만 타이밍이 안 맞아서 계속 포크를 못 잡고 굶어죽는 상황이 발생할 수 있음
        
- **해결 방법**
    - Deadlock  
      → 자원 순서 지정 등
    - Starvation  
      → 공정 큐(FIFO Queue) / 집사(별도 스레드)가 허가하는 방식 / Backoff + Random Delay

### 2.5 Deadlock
    
동기화 문제에서 가장 유명한 사고이다.  
”여러 프로세스/스레드가 서로의 자원을 얻기 위해 영원히 대기하는 상태”를 말한다.

- **Deadlock의 네 가지 조건**
    1. 상호 배체(Mutual Exclusion) → 한 자원은 한 프로세스만 사용 가능
    2. 점유 대기(Hold and Wait) → 자원을 이미 가지고 있는 상태에서 다른 자원을 요청하며 대기
    3. 비선점(Non-preemption) → 이미 할당된 자원을 강제로 뺏을 수 없음
    4. 환형 대기(Circular Wait) → 서로 요청하는 자원이 원형 구조를 이룸.
       
- **Deadlock을 예방하는 방법**
    
    위의 네 가지 조건 중 하나라도 깨면 된다.
    
- **해결 전략**
    - **예방(Prevention)** → 위 조건 중 하나가 애초에 발생하지 않도록 함
    - **회피(Avoidance)** → 데드락이 날지 판단하고, 안전 상태만 허용 (대표 알고리즘: Banker’s Algorithm)
    - **탐지  & 회복(Detection & Recovery)** → 주기적으로 탐지 후 처리
      
### 2.6 Starvation
    
특정 스레드/프로세스가 자원을 계속 요구하지만, 스케줄링/락 정책 때문에 영원히 서비스 받지 못하는 상태를 말한다.

- **해결 전략**
    - **Aging**: 오래 기다린 프로세스의 우선순위를 점점 올림
    - **공정 락(Fair Lock)**: 먼저 요청한 순서대로 자원을 줌(FIFO)

⇒ 동기화 문제는 단지 “락 하나 걸고 말고”가 아니라, 버퍼에 대한 조건이나 Deadlock, Starvation과 같은 부수적인 결과에 대한 것도 고려해야 한다.
    
## 3 동기화를 위한 하드웨어적 기반
    
동기화의 요구는 결국 “동시에 하나의 스레드만 실행”과 “서로 같은 상태를 보는 것”이다.  
→ 이것을 지원해주는 것은 OS보다 아래의 하드웨어이다.  
→ 여기에서는 이런 동기화를 위한 하드웨어 기반을 배운다.

### 3.1 메모리 일관성 문제(Memory Consistency Problem)
    
“멀티 코어 + 캐시”로 인해 발생하는 문제이다.

각 코어는 자기만의 L1/L2 캐시를 가지고 있다.  
→ 한 스레드가 값을 바꿨다고 해서 바로 다른 코어의 캐시나 메모리에 반영되는 것이 아니다.

- **발생 원인**
    - **캐시 지연**  
      → 각 코어 캐시에 값이 남아 있고, 아직 메모리에 반영 안됨.
    - **명령어 재배치(reordering)**  
      → 컴파일러/CPU가 성능을 위해 명령 순서를 바꿔버림
      → 변수의 값을 할당하는 순서가 바뀌면 조건에 의한 실행 결과가 바뀔 수 있다.
- **해결 방법**
    - 캐시 일관성 프로토콜(MESI 등)
    - 메모리 배리어(fence)
    - 메모리 모델(JMM 등)
      
### 3.2 Atomic Instruction (원자적 연산)
    
CPU는 원자적 연산을 위해 다음과 같은 하나의 명령으로 RMW(Read-Modify-Write)가 되는 것을 지원한다.

test-and-set, CAS, fetch-and-add, atomic increment 등  
→ OS/라이브러리는 이 위에서 동기화 도구를 구현한다.

(근데 CPU가 제공하는 원자적 연산 만으로는 안되고, 다른 기법이 추가적으로 필요하다.)
    
### 3.3 Test-and-Set (TAS)
    
> 메모리의 값을 읽으면서 바꾸고, 바꾸기 전 값을 반환하는 원자적 연산.  
> (하드웨어 레벨에서 지원)


```java
bool test_and_set(bool *target) {
    bool old = *target;
    *target = true;
    return old;
}
```

→ 1(`true`)로 바꾸는 경우, 두 CPU에서 동시에 실행하면 두 코어 모두 `false`를 반환 받을 수 없음.
    
### 3.4 Compare-and-Swap (CAS)
    
> 메모리의 값이 기대하는 값과 같은 경우 새로운 값을 할당하고, 다른 경우에는 실패하는 원자적 연산.  
> → 비교(Compare)와 교체(Swap)을 하나의 원자적 연산으로 수행한다.  
> → 조건부 변경


```java
bool compare_and_swap(int* addr, int expected, int new_val) {
    if (*addr == expected) {
        *addr = new_val;
        return true;
    } else {
        return false;
    }
}
```
    
### 3.5 인터럽트 비활성화(Disable Interrupts)
    
올드한 개념이지만 중요하다.

싱글 코어 시절에는 인터럽트가 발생한 경우에만 CPU가 갑자기 다른 코드로 튀었다.  
→ 인터럽트를 잠시 끄면 현재 코드가 끝날 때까지 Context Switching이 일어나지 않는다.

- **현대 CPU에서 인터럽트 비활성화로도 못 막는 것들**
    
    CPU 내부 재배치(명령어 재정렬, 파이프라인 최적화, 메모리 순서 바꿈),
    
    다른 코어의 실행 등
        
### 3.6 Memory Barrier / Fence
    
명령어 재배치 및 메모리 가시성을 제어하기 위한 도구이다.

> Memory Barrier(Fence)는 그 지점 전/후의 메모리 접근(load/store)이 특정 순서를 유지하도록 CPU/컴파일러에게 강제하는 명령이다.

→ CPU/컴파일러 최적화 과정에서, fence 전의 실행한 메모리 연산은 fence 이후로 넘어가지 않는다. & fence 이후의 연산이 fence 이전으로 끌려 올라가지 않는다.

```java
// Thread A
data = 42;
store_fence();      // 이후의 store가 앞질러 가지 못하게
flag = true;

// Thread B
if (flag) {
    load_fence();   // 이전의 load들이 뒤로 밀리지 않게
    print(data);
}
```

→ data 변수에 42가 저장되는 것이 flag가 true가 되는 것보다 반드시 먼저 발생하기 때문에, 항상 42가 출력된다.

- **종류**
    
    Load Fence → 읽기 연산의 순서를 보장
    
    Store Fence → 쓰기 연산의 순서를 보장
    
    Full Fence → 읽기/쓰기 모두의 순서를 보장
    
- **언어 레벨**
    
    Java의 `volatile`, `synchronized` 등은 내부적으로 fence를 포함한다.
            
## 4 소프트웨어 동기화 도구
    
이는 하드웨어 수준의 원자연 연산(TAS, CAS 등)이 없는 소프트웨어만으로 동기화를 구현하는 관점의 알고리즘이다.  
이 알고리즘들은 결국 사라졌다. 이 내용을 알아보자.

### 4.1 Dekker’s algorithm(데커 알고리즘)
    
가장 오래된 Mutual Exclusion 알고리즘으로, 두 개의 프로세스가 있을 때 Critical Section을 보호하기 위해 고안되었다.

flag와 turn을 사용해서 자기 turn인 경우에만 임계 구역에 진입할 수 있게 하는 알고리즘이다.

- **단점**
    - **두 스레드만 지원**
        
        알고리즘 상 임계구역에 진입 후에 turn을 직접 상대로 바꾸기 때문에, 두 스레드만 가능한 알고리즘이다.
        
    - **Busy Waiting 방식**
        
        busy waiting 방식으로 while문을 계속 돌면서 CPU를 점유하는 방식이다.
        
    - **현대 CPU 메모리 모델과 맞지 않음**
        
        이 알고리즘은 변수 값 변경이 순차적으로 이루어져야 한다.  
        → 현대 CPU의 메모리 모델에서는 fence가 필요하고, 순수 소프트웨어만으로 구현이 어렵다고 할 수 있다.
            
### 4.2 Petersons’s algorithm(피터슨 알고리즘)
    
```java
flag[i] = true;
turn = j;
while (flag[j] && turn == j) {
    // 기다림
}

// --- critical section ---

flag[i] = false;
```

진입 의사를 밝히고, 상대에게 turn을 넘긴 후에 busy waiting으로 상대의 critical section 작업이 끝나길 기다린 후에 critical section에 진입한다.

- **단점**
    
    데커 알고리즘과 마찬가지로 “두 스레드만 지원”, “Busy Waiting”, “현대 멀티코어 CPU + 메모리 재배치 환경에서의 소프트웨어 만으로 구현 힘듦”의 단점이 있다.
        
### 4.3 Bakery algorithm (Lamport’s Bakery Alogrithm)
    
N개의 스레드를 대상으로 하는 일반화된 Mutual Exclusion 알고리즘이다.

빵집 번호표 시스템에서 착안해서 Bakery 알고리즘이고, 두 개 이사의 여러 스레드에 대해서도 공정하게 Mutual Exclusion을 보장한다.

- **아이디어**
    
    각 스레드는 “번호표(ticket)”을 뽑고, 번호표 번호가 가장 낮은 스레드가 임계 구역(Critical Section)에 들어간다.
    
- **공유 변수**
    
    `choosing[i]` → i번 스레드가 번호표를 뽑는 중인지 여부
    
    `number[i]` → i번 스레드가 뽑은 번호표 번호
    
- **장점**
    
    N개의 스레드 확장 가능
    
    기아 현상 없이 공정함 보장
    
- **단점**
    
    구현이 매우 복잡함
    
    Busy Waiting으로 while문 기반 대기임
    
    등등
        
### 4.4 실전에서 안 쓰이는 이유
- **현대 CPU의 메모리 모델에서 안전하지 않음**
    
    CPU의 load/store 재배치
    
    서로 다른 코어에 캐시가 있어서 값이 즉지 반영 안됨(가시성 문제)
    
    fence가 없으면 명령어가 수행되는 순서가 보장되지 않음
    
    → 위의 세 알고리즘 모두 재배치에 의해 mutual exclusion이 깨질 수 있음
    
- **Busy Waiting이 과도함**
    
    세 알고리즘 모두 소프트웨어만으로 구현하다보니 while문을 활용한 방식으로 대기하고, 이는 CPU를 점유함.
    
- **알고리즘이 복잡함**
    
    단순 Lock/Unlock이 아니라 더 복잡함.
    
- **하드웨어 기반 Atomic Instruction(TAS, CAS)이 훨씬 강력함**
    
    소프트웨어 기반 알고리즘을 사용할 이유가 없음
            
## 5 OS 레벨 동기화 도구
### 5.1 Mutex(뮤텍스)
- **특징**
    
    소유권(ownership) 개념이 있어서 락을 획득한 스레드만 해제할 수 있다.  
    → 획득에 실패하면 OS 커널로 진입 후 대시 큐(Wait Queue)로 들어감.
    
    CAS + 커널 wait queue로 구현됨.
    
- **동작 과정**
    
    임계 구역(Critical Section)에 진입하기 전에 락을 획득해야 함.
    
    - **락 획득 성공**
        
        CAS로 락 획득 → 성공 → 임계 구역 진입
        
    - **락 획득 실패**
        
        CAS 실패 → OS로 전환 → wait queue에 넣고 sleep
        
    - **락 해제**
        
        CAS로 locked에서 unlocked로 변경  
        wait queue에서 스레드 하나를 깨움
        
- **장점**
    
    커널 레벨에서 wait queue에 넣고 대기시키기 때문에 CPU를 점유하지 않음
    
- **단점**
    
    커널 모드로 전환하는 모드 전환 비용이 있음 → 속도가 느림  
    → 자주 lock/unlock하면 오버헤드 증가
    
- **어떻게 waiting queue에서 기다리는 스레드를 깨우는가?**
    
    커널은 각 뮤텍스 별로 blocked 된 스레드를 식별할 수 있다.  
    → 그리고 unlock이 호출되면 시스템 콜로(이때 모드 전환) 커널이 그 중 하나를 깨우게 함.  
    → runnable 상태로 변경됨.
    
- **커널 모드로 전환하는 비용?**
    
    wait queue에 넣고 다시 깨울 때 시스템 콜을 호출하면서 모드가 전환된다.
    
    모드가 전환되면 CPU 전체의 실행 환경이 바뀐다.  
    → CPU Privilege Level 변경 비용  
    → 스택 포인터 교체(유저 모드와 커널 모드의 메모리 공간은 분리되기 때문)  
    → 레지스터 교체  
    → 파이프라인 flush (브랜치 예측 실행된 경우 수백 사이클이 영향 받을 수 있음)  
    ⇒ Context Switching 보다는 싼 비용이지만 적은 비용은 아니다.
        
### 5.2 Semaphore(세마포어)
    
뮤텍스가 “동시에 한 명만 들어갈 수 있는 락”이라면,  
세마포어는 “동시에 여러 명이 들어갈 수도 있는 락”이다.

- **종류**
    
    Binary Semaphore → 값이 0 또는 1.
    
    Counting Semaphore → 값이 0 ~ N. 동시에 N기의 스레드가 접근 가능함.
    
- **동작 원리**
    
    `P(S)` 또는 `wait(S)` → 자원 얻기.  
    → S가 0보다 크면 자원을 얻고 S가 1줄음.  
    → S가 0이면 스레드를 sleep 시킴.
    
    ⇒ S가 음수일 경우는 그 절댓값 만큼 기다리는 스레드가 있다는 의미이다.
    
    `V(S)` 또는 `signal(S)` → 자원 반납
    
- **뮤텍스와의 차이**
    
    뮤텍스는 일단 하나의 스레드만 접근 가능.
    
    또 뮤텍스는 락을 얻은 해당 스레드만 락을 풀 수 있음.  
    → 세마포어는 그 스레드가 아니어도 사실 언락이 가능함.  
    → 주의해야 함.
        
### 5.3 Condition Variable(조건 변수)
    
> 조건이 충족될 때까지 스레드를 “원자적으로 unlock하고 sleep시키는” 동기화 도구이다.  
> 그리고 다른 스레드가 조건을 만족 시키면 wake-up 시킨다.

- **필요 이유**
    
    뮤텍스만 있는 경우  
    → 락을 잡고 있는 상태에서 대기하면 교착이 발생함.
    
    조건 변수는 조건이 충족될 때까지 뮤텍스를 자동으로 unlock하고 대기하게 한다.  
    ⇒ `unlock → block → wake → lock`을 원자적으로 수행한다.  
    (이 원자적이라는 말은 단일 명령으로 처리한다는 것이 아니라, 올바른 순서를 보장한다는 것이다.)
    
    ex) 생산자-소비자 문제에서 소비자가 버퍼의 락을 잡고 대기해버리면 생산자가 버퍼에 접근할 수 없다. 그래서 버퍼에 대한 락을 잡고 조건이 만족되길 기다리게 하는 것이다.
        
### 5.4 Monitor(모니터)
    
“뮤텍스 + 조건 변수” 조합을 객체 단위로 캡슐화한 것이다.

자바의 `synchronized` 블록이 대표적인 Monitor 구현이다.

- **구성 요소**
    
    ```java
    monitor M {
        mutex lock
        condition variables cv1, cv2, ...
        shared data
    }
    ```
    
    뮤텍스와 조건 변수, 공유 데이터로 이루어진 **객체**이다.
    
    공유 데이터는 모니터 내부에서만 접근 가능하다.
    
    모니터의 모든 메서드의 시작과 끝에는 락을 잡고 푸는 과정이 포함되어 있다.
    

⇒ 모니터는 락을 잡고 조건을 기다리는 것을 안전하게 사용하도록 만든 추상화된 동기화 도구이다.
    
### 5.5 Spinlock
    
락이 풀릴 때까지 while-loop로 계속 확인하는 락이다.

Busy Waiting 기반이다.

TAS나 CAS로 구현된다.

- **언제 사용?**
    
    뮤텍스는 커널 모드로 진입하는 비용이 필요하다.
    
    그래서 아주 짧은 순간의 동기화만 필요하다면, 스핀락으로 하는 것이 더 빠를 수 있다.
    
    (특히 커널 내부에서 많이 사용한다.)
            
## 6 메모리 모델과 동기화
### 6.1 CPU 캐시 일관성 (MESI 프로토콜 개념)
- **문제**
    
    각 코어는 자기만의 L1/L2 캐시를 가지고 있다.  
    → 같은 전역 변수라도 각 코어의 캐시에서 값이 다를 수 있다.  
    → 동기화 없이 공유 변수를 사용하면 서로 보는 값이 다를 수 있음.
    
- **MESI 프로토콜**
    
    캐시 라인 상태를 관리하는 프로토콜을 말한다.
    
    **M (Modified)** → 이 코어 캐시에만 있고, 메인 메모리과 값이 다름(변경됨)
    
    **E (Exclusive)** → 이 코어만 가지고 있고, 메모리와 값이 동일함
    
    **S (Shared)** → 여러 코어 캐시에 복사본이 있음, 모두 메모리와 값 동일
    
    **I (Invalid)** → 이 라인은 무효(더이상 유효한 데이터가 아님)
    
    - **원리**
        
        어떤 코어가 어떤 공유 변수를 쓰려고 하면, 다른 코어들 캐시에 있는 해당 변수 라인을 Invalid로 만들거나 값을 전파해서 Shared로 만들어야 한다.  
        → 캐시 간 **일관성(Coherence)**을 보장한다.  
        → 최종적으로는 모두 같은 최신 값을 보게 한다.  
        
        “그 최신 값이 언제 다른 스레드에게 보이느냐”는 언어/하드웨어의 메모리 모델에 따라 다르다.
            
### 6.2 Load/Store Reordering(명령어 재배치)

컴파일러/CPU는 성능을 위해 독립적인 명령어 끼리의 순서를 바꿔버릴 수 있다.

또한 Load/Store를 파이프라인/버퍼에 쌓아두로 나중에 밀어넣을 수 있다.

→ 이게 싱글 스레드 기준으로는 결과가 같음.

⇒ “코드가 순서대로 실행된다고 믿으면 안 된다.”

이것을 제어하는 추상 규칙이 **메모리 모델**이고,  
그것을 구현하는 것이 **fence(베리어), volatile, synchronized**같은 것들이다.
    
### 6.3 Java Momory Model(JMM)
    
> 자바에서 여러 스레드가 메모리를 읽고/쓰는 행동이 어떻게 보장될 것인가를 정의한 규칙 세트이다.

- **JMM이 정하는 것**
    1. 어떤 쓰기가 어떤 읽기에 보이는지 (visibility)
    2. 어떤 순서로 일어난 것처럼 보이도록 허용할지 (ordering)
    3. 어떤 상황에서 재배치가 허용되고, 언제 막아야 하는지
- **JMM의 큰 그림**
    
    JMM은 논리적인 **happens-before** 개념으로 정의된다.
    
    `A happend-before B`  
    → A의 결과(쓰기 등)는 B에서 반드시 보인다.  
    → A와 B의 상대적인 순서를 뒤집는 최적화는 허용되지 않는다.
    
    이는 명령어 재정렬 같은 것을 막는 것이 아니라, 재정렬 결과가 프로그램의 동작을 바꿀 수 없도록 보장한다는 것이다.
        
### 6.4 Happens-before 관계
    
자바에서 “메모리 가시성과 순서를 보장하는 관계”를 표현하는 말이다.

> A happens-before B  
> → A가 논리적으로 먼저 일어났고, A에서 한 쓰기는 B에서 반드시 보인다.

1. **프로그램 순서 규칙(Program Order Rule)**
    
    한 스레드 안에서 소스 코드 순서대로 happens-before가 성립.  
    → 자기 자신에 대해서만 의미가 있고, 다른 스레드가 볼 때는 여전히 뒤집힐 수 있다.
    
2. **Monitor Lock 규칙 (synchronized)**
    
    같은 락에 대한 접근에서, 다른 스레드가 해당 락을 얻고 수행한 결과는 다른 스레드가 같은 락을 얻고 들어갔을 때 반드시 보인다.
    
3. **volatile 변수 규칙**
    
    `volatile` 변수에 대한 **쓰기(write)**는 그 이후에 `volatile` 변수를 **읽는(read)** 모든 스레드에서 보이도록 한다.
    
4. **Thread start / join 규칙**
    
    스레드 `start()`를 호출하기 전에 부모 스레드가 한 작업은 새로 시작한 스레드에서 반드시 보인다.
    
    스레드가 한 작업은 `join()`된 이후에 리턴을 받은 스레드에서 반드시 보인다.
    
5. **Transitivity**
    
    A happens-before B이고, B happens-before C이면,  
    A happens-before C도 성립한다.
        
### 6.5 volatile 키워드와 atomicity 보장 범위
- **volatile이 보장하는 것 (JMM 관점)**
    - **가시성(visibility)**
    - **순서(ordering)**
        
        volatile 변수 뿐만 아니라 그 이전에 변경된 일반 변수들도 같이 flush되는 효과가 일어난다.  
        → volatile 변수에 대한 접근 이후에 오는 연산은 그 접근 이전에 있는 것이 반드시 반영된다.
        
- **volatile이 보장하지 않는 것**
    
    오해하기 쉬운데, volatile은 복합 연산의 원자성을 보장하지 않는다.  
    → volatile 변수에 대한 증감 연산은 원자적이지 않음.

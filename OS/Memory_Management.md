# 메모리 관리(Memory Management)
## 1 주소 공간(address space)
    
주소 공간이란, 프로세스가 접근할 수 있는 메모리 주소들의 범위(집합)을 말한다.  
→ “이 프로세스가 사용할 수 있는 메모리는 여기부터 여기까지”를 지정한 논리적 공간이다.  
→ 각 프로세스마다 독립적인 주소 공간을 가짐 → 서로 간섭하지 않음.  
(주소 공간의 크기는 CPU 주소 버스(bit 수)에 의해 결정된다.)

### 1.1 논리 주소 vs 물리 주소
- **논리 주소(Logical Address)**
    
    프로그램이 보는 주소(CPU가 생성하는 주소)
    
- **물리 주소(Physical Address)**
    
    실제 RAM 상의 주소(하드웨어가 접근하는 주소)
    
- **차이의 이유**
    
    운영체제는 여러 프로그램을 동시에 실행함  
    → 각 프로그램이 독립된 주소를 사용한다고 착각하게 만들어야 한다.  
    → 그래서 논리 주소를 실제 물리 주소로 변환하는 과정이 필요하다.
        
### 1.2 주소 변환(Address Translation)
    
CPU가 메모리에 접근할 때 “논리 주소 → 물리 주소”로 바꾸는 과정이다.  
→ 이를 수행하는 하드웨어가 **MMU(Memory Management Unit)**이다.

이 매핑 관계를 OS는 **페이지 테이블(Page Table)** 또는 **세그먼트 테이블(Segment Table)**로 관리한다. (뒤의 가상 메모리 참고)
    
### 1.3 MMU(Memory Management Unit)
    
CPU 안에 있는 하드웨어 장치로, 모든 메모리 접근을 가로채서 주소 변환을 수행한다.

(캐시/페이징/TLB 등과 협력하여 성능을 향상시킨다. → 뒤의 가상 메모리 참고)
    
## 2 연속 메모리 할당(Contiguous Memory Allocation)

**연속 메모리 할당**은 운영체제가 프로세스 하나를 메모리의 연속된 공간에 올려두는 방식이다.  
→ 한 프로그램의 모든 코드, 데이터, 스택이 물리 메모리 내에서 한 덩어리로 배치된다.  
→ 여러 프로세스를 동시에 실행할 때, 공간의 낭비(단편화)가 생기기 때문에 나중에 **페이징(Paging)** 같은 비연속 방식이 등장한다.

### 2.1 고정 분할 / 가변 분할
- **고정 분할(Fixed Partitioning)**
    
    메모리를 일정한 크기의 여러 영역으로 미리 나눔.  
    → 단순, 빠른 할당 가능  
    But, **내부 단편화** 발생
    
- **가변 분할(Variable Partitioning)**
    
    프로세스 크기에 맞게 동적으로 나눔  
    → 메모리 낭비가 적음  
    But, **외부 단편화** 발생 (프로세스가 중간에 종료되면서 빈틈이 생기고, 외부 단편화가 발생함)
        
### 2.2 내부 단편화 vs 외부 단편화
- **내부 단편화(Internal Fragmentation)**
    
    고정 크기 파티션의 크기와 프로세스 크기가 일치하지 않음  
    → 할당된 영역 안에서 실제로 사용하지 않는 낭비되는 공간이 생김  
    → 내부 단편화
    
    해결 방법: 가변 분할(외부 단편화 발생), 블록 단위 세분화(관리 오버헤드 증가)
    
- **외부 단편화(External Fragmentation)**
    
    가변 크기 파티션에서 프로세스의 생성/종료가 반복됨  
    → 할당되지 않은 작은 틈새 공간이 여러 곳에 흩어짐  
    → 외부 단편화
    
    해결 방법: 압축 또는 페이징
        
### 2.3 압축(Compaction)
    
외부 단편화를 줄이기 위한 방법이다.

프로세스들이 메모리 여기저기 흩어져 있음  
→ 한쪽으로 모아서 연속된 큰 공간을 만드는 작업이다.

But, 모든 데이터를 옮겨야 하기 때문에 비효율적임  
→ 실제로는 잘 사용하지 않고, 페이징(Paging)으로 해결한다.
    
## 3 가상 메모리(Virtual Memory)

가상 메모리는 “실제 물리 메모리보다 더 큰 메모리를 가진 것처럼 보이게 하는 기술”이다.

프로세스마다 독립된 주소 공간을 제공 + 실제 물리 메모리에는 필요한 부분만 올려서 실행

### 3.1 특징 요약
    
보호(Protection) → 프로세스 간 메모리 접근 격리

효율성(Efficiency) → 필요한 페이지만 메모리에 올림

확장성(Flexibility) → 물리 메모리보다 큰 프로그램 실행 가능
    
### 3.2 페이징(Paging) / 세그먼테이션(Segmentation)
    
세그먼테이션 = 가변 분할(Variable Partitioning)

| 구분 | 페이징 (Paging) | 세그먼테이션 (Segmentation) |
| --- | --- | --- |
| **단위** | 고정 크기(Page) | 논리적 단위(Segment) |
| **크기** | 모든 페이지 동일 크기 (ex. 4KB) | 코드, 데이터, 스택 등 각 세그먼트 크기 다름 |
| **주소 구성** | 페이지 번호 + 페이지 내 오프셋 | 세그먼트 번호 + 세그먼트 내 오프셋 |
| **단편화** | 내부 단편화 발생 가능 | 외부 단편화 발생 가능 |
| **장점** | 관리 단순, 메모리 효율 ↑ | 논리적 구조 반영, 보안/보호에 유리 |
| **단점** | 프로그램 구조 반영 어려움 | 세그먼트 크기 불균형 시 단편화 |

**페이지(Page)** → 프로세스의 논리 주소 공간을 나눈 것.  
**프레임(Frame)** → 물리 메모리 공간을 나눈 것.  
⇒ 페이지와 프레임 크기는 동일하다.  
⇒ 그래야 가상 주소의 한 페이지를 물리 메모리의 한 프레임에 그대로 매핑할 수 있다.
    
### 3.3 페이지 테이블(Page Table)
    
**가상 주소(페이지 번호)**를 **실제 물리 주소(프레임 번호)**로 매핑하는 표

가상 주소: [Page Number | Offset]  
→ 매핑 (Page Number를 Frame Numebr로 변환)  
→ 물리 주소: [Frame Number | Offset]  
(매핑 시에 Offset은 변하지 않는다.)

- **문제점**
    
    Page Table은 모든 프로세스마다 존재함  
    → 용량이 매우 커질 수 있음  
    → **Multi-Level Paging**이나 **TLB**를 사용해서 보완한다.
    
    저장 위치가 **메인 메모리(RAM)**이다.  
    → 느림 → **TLB**를 사용해서 보완한다.
        
### 3.4 TLB(Translation Lookaside Buffer)
    
“페이지 테이블 캐시”

자주 사용하는 페이지 매핑 정보를 **CPU 내부의 캐시**에 저장하여 변환 속도를 높이는 장치다.  
→ 즉, TLB는 그냥 CPU 내부에 있는 캐시다.

**TLB Hit** → TLB 매핑 정보 있음 → 빠른 변환  
**TLB Miss** → TLB 매핑 정보 없음 → Page Table 접근 필요
    
### 3.5 페이지 폴트(Page Fault)
    
CPU가 접근한 페이지가 현재 메모리에 없을 수 있다.  
→ **페이지 폴트(Page Fault)** 발생  
→ 디스크에서 해당 페이지를 불러온다.

- **절차**
    
    CPU가 페이지 접근 → TLB, 페이지 테이블 확인  
    → 해당 페이지가 없음 → 페이지 폴트 발생  
    → OS가 디스크에서 페이지를 읽어 RAM에 적재  
    → 페이지 테이블 갱신  
    → 다시 CPU의 페이지 접근
    

⇒ 알고리즘에 따라 우선순위가 낮은 것은 필요할 때만 디스크에서 불러오게끔 할 수 있다. ⇒ 메모리 사용 최적화
    
### 3.6 Demand Paging / Swapping
    
**Demand Paging**  
→ 필요할 때만 페이지를 메모리에 로드하는 기법

**Swapping**  
→ 메모리가 부족하면 OS가 비활성 프로세스 전체를 디스크로 내보냄(Swap Out)  
→ 다시 필요하면 다시 불러온다.(Swap In)  
⇒ Swapping은 페이지 단위가 아니라 프로세스 단위이다. 그래서 디스크 I/O가 커서 상대적으로 느리고, 페이징보다 비용이 크다.

Swapping은 메모리가 매우 부족할 경우에 수행됨.
    
## 4 페이지 교체(Page Replacement) 알고리즘

메모리에 빈 공간이 없을 때, 어떤 페이지를 내보낼지 결정하는 과정

### 4.1 알고리즘
- **FIFO(First-In First-Out)**
    
    가장 먼저 들어온 페이지를 가장 먼저 내보냄  
    → 
    
- **OPT(Optimal, 최적 알고리즘)**
    
    “앞으로 가장 오랫동안 사용되지 않을 페이지”를 교체  
    → 실제로는 미래의 접근 패턴을 알 수 없기 때문에 구현 불가능  
    → 성능 비교의 기준으로만 사용한다.
    
- **LRU(Least Recently Used)**
    
    가장 오랫동안 사용되지 않은 페이지를 교체  
    → 최근에 사용된 페이지는 앞으로도 자주 사용할 가능성이 높다는 말.  
    → 실제 시스템에서 가장 많이 사용됨.
    
- **LFU(Least Frequently Used)**
    
    사용 빈도가 가장 낮은 페이지를 교체  
    (사용 횟수를 카운트하고, 가장 덜 사용된 페이지를 제거)  
    → 최근은 자주 사용됐지만, 과거 기록 때문에 제거될 수 있다.
    
- **Clock (Second Chance) 알고리즘**
    
    각 페이지에 **참조 비트(reference bit)**를 둔다.  
    → 참조 비트가 1이면 0으로 바꾸고 넘어감  
    → 참조 비트가 0이면 교체  
    → Linux 등 실제로 많이 사용되는 실용적 방식이다.  
    (LRU를 근사한 효율적 구현이다.)
    
- **NRU(Not Recently Used)**
    
    가장 덜 최근에 사용되고 수정도 안 된 페이지를 우선 교체  
    (구현이 간단해 LRU의 근사 알고리즘으로 사용된다.)
        
### 4.2 Thrashing(스래싱) 개념과 원인
    
페이지 교체가 너무 자주 발생해서 CPU가 거의 디스크 I/O만 하게 되는 현상

- **현상**  
    
    프로세스가 필요한 페이지가 메모리에 없는 경우가 많음  
    → 페이지 폴트(Page Fault) 자주 발생  
    → CPU는 계산보다 페이지 교체 처리에 대부분의 시간을 소비  
    → 시스템 성능 하락
    
- **원인**
    - 동시에 실행 중인 프로세스 수가 너무 많음  
    - Working Set이 너무 큼(프로세스가 한 번에 필요한 페이지 수가 물리 메모리보다 많음)  
    - 부적합한 교체 정책으로 인해 자주 쓰는 페이지가 계속 교체됨  
    - 많은 프로세스를 동시에 실행시켜야 됨(과도한 멀티프로그래밍)
      
- **해결 방법**  
    
    프로세스 수 조절
    
    적절한 교체 알고리즘 선택
